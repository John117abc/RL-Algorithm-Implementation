{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 这一节，主要实现贝尔曼方程的计算",
   "id": "da1ed527d8582b3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:05:51.459072Z",
     "start_time": "2025-11-18T02:05:51.455229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step1：导入所有必要的库\n",
    "import time\n",
    "from typing import Optional, Union, List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "from IPython.display import display, clear_output"
   ],
   "id": "610d6718f87da0b3",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "由于在网格世界中，我们需要频繁检查智能体是否碰到了障碍物，使用`np.array_equal`比较数组内容。\n",
   "id": "96208bd23e8c67d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:05:51.512213Z",
     "start_time": "2025-11-18T02:05:51.508333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step2：辅助函数\n",
    "def arr_in_list(array, _list):\n",
    "    \"\"\"\n",
    "    检查一个numpy数组是否在另一个列表中\n",
    "    \"\"\"\n",
    "    for element in _list:\n",
    "        if np.array_equal(element, array):\n",
    "            return True\n",
    "    return False"
   ],
   "id": "cfdfd896adfedfa5",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:05:51.584663Z",
     "start_time": "2025-11-18T02:05:51.563926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step3：可视化工具\n",
    "class Render:\n",
    "    \"\"\"\n",
    "    网格世界可视化工具类\n",
    "    \"\"\"\n",
    "    def __init__(self, target: Union[list, tuple, np.ndarray],\n",
    "                 forbidden: Union[list, tuple, np.ndarray], size: int = 5):\n",
    "        self.agent = None\n",
    "        self.target = np.array(target)\n",
    "        self.forbidden = [np.array(fob) for fob in forbidden]\n",
    "        self.size = size\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        self.trajectory = []\n",
    "        self.reset_canvas()\n",
    "    # 创建画布\n",
    "    def create_canvas(self, figsize: Tuple[int, int] = None) -> None:\n",
    "        if self.fig is not None:\n",
    "            plt.close(self.fig)\n",
    "        if figsize is None:\n",
    "            figsize = (10, 10)\n",
    "        self.fig, self.ax = plt.subplots(figsize=figsize, dpi=self.size * 20)\n",
    "        if self.agent is not None:\n",
    "            self.agent.remove()\n",
    "        self.agent = patches.Arrow(-10, -10, 0.4, 0, color='red', width=0.5)\n",
    "    # 初始化网格\n",
    "    def init_grid(self) -> None:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "\n",
    "        self.ax.xaxis.set_ticks_position('top')\n",
    "        self.ax.invert_yaxis()\n",
    "        self.ax.xaxis.set_ticks(range(0, self.size + 1))\n",
    "        self.ax.yaxis.set_ticks(range(0, self.size + 1))\n",
    "        self.ax.grid(True, linestyle=\"-\", color=\"gray\", linewidth=\"1\", axis='both')\n",
    "        self.ax.tick_params(bottom=False, left=False, right=False, top=False,\n",
    "                           labelbottom=False, labelleft=False, labeltop=False)\n",
    "\n",
    "        for y in range(self.size):\n",
    "            self.write_word(pos=(-0.6, y), word=str(y + 1), size_discount=0.8)\n",
    "            self.write_word(pos=(y, -0.6), word=str(y + 1), size_discount=0.8)\n",
    "\n",
    "        self.ax.add_patch(self.agent)\n",
    "    # 重置画布\n",
    "    def reset_canvas(self, clear_trajectory: bool = True, figsize: Tuple[int, int] = None) -> None:\n",
    "        self.create_canvas(figsize)\n",
    "        self.init_grid()\n",
    "        for pos in self.forbidden:\n",
    "            self.fill_block(pos=pos)\n",
    "        self.fill_block(pos=self.target, color='darkturquoise')\n",
    "        if clear_trajectory:\n",
    "            self.trajectory = []\n",
    "\n",
    "    def fill_block(self, pos: Union[list, tuple, np.ndarray], color: str = '#EDB120',\n",
    "                   width: float = 1.0, height: float = 1.0) -> patches.Rectangle:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        return self.ax.add_patch(\n",
    "            patches.Rectangle((pos[0], pos[1]), width=width, height=height,\n",
    "                            facecolor=color, fill=True, alpha=0.90)\n",
    "        )\n",
    "    # 画随机线\n",
    "    def draw_random_line(self, pos1: Union[list, tuple, np.ndarray], pos2: Union[list, tuple, np.ndarray]) -> None:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        offset1 = np.random.uniform(low=-0.05, high=0.05, size=1)\n",
    "        offset2 = np.random.uniform(low=-0.05, high=0.05, size=1)\n",
    "        x = [pos1[0] + 0.5, pos2[0] + 0.5]\n",
    "        y = [pos1[1] + 0.5, pos2[1] + 0.5]\n",
    "        if pos1[0] == pos2[0]:\n",
    "            x = [x[0] + offset1, x[1] + offset2]\n",
    "        else:\n",
    "            y = [y[0] + offset1, y[1] + offset2]\n",
    "        self.ax.plot(x, y, color='g', scalex=False, scaley=False)\n",
    "    # 画执行动作\n",
    "    def draw_action(self, pos: Union[list, tuple, np.ndarray], toward: Union[list, tuple, np.ndarray],\n",
    "                    color: str = 'green', radius: float = 0.10) -> None:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        if not np.array_equal(np.array(toward), np.array([0, 0])):\n",
    "            self.ax.add_patch(\n",
    "                patches.Arrow(pos[0] + 0.5, pos[1] + 0.5, dx=toward[0], dy=toward[1],\n",
    "                            color=color, width=0.05 + 0.05 * np.linalg.norm(np.array(toward) / 0.5),\n",
    "                            linewidth=0.5)\n",
    "            )\n",
    "        else:\n",
    "            self.draw_circle(pos=tuple(pos), color='white', radius=radius, fill=False)\n",
    "    # 画圈\n",
    "    def draw_circle(self, pos: Union[list, tuple, np.ndarray], radius: float,\n",
    "                    color: str = 'green', fill: bool = True) -> patches.Circle:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        return self.ax.add_patch(\n",
    "            patches.Circle((pos[0] + 0.5, pos[1] + 0.5), radius=radius,\n",
    "                         facecolor=color, edgecolor='green', linewidth=2, fill=fill)\n",
    "        )\n",
    "\n",
    "    def write_word(self, pos: Union[list, np.ndarray, tuple], word: str, color: str = 'black',\n",
    "                   y_offset: float = 0, size_discount: float = 1.0) -> None:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        font_size = size_discount * (30 - 2 * self.size)\n",
    "        self.ax.text(pos[0] + 0.5, pos[1] + 0.5 + y_offset, word,\n",
    "                    size=font_size, ha='center', va='center', color=color)\n",
    "    # 更新智能体\n",
    "    def upgrade_agent(self, pos: Union[list, np.ndarray, tuple], action: Union[list, np.ndarray, tuple],\n",
    "                      next_pos: Union[list, np.ndarray, tuple]) -> None:\n",
    "        self.trajectory.append([tuple(pos), action, tuple(next_pos)])\n",
    "    # 展示框架\n",
    "    def show_frame(self, t: float = 0.2, close_after: bool = False) -> None:\n",
    "        if self.fig is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        # 在Jupyter中显示\n",
    "        clear_output(wait=True)\n",
    "        display(self.fig)\n",
    "        if close_after:\n",
    "            plt.close(self.fig)\n",
    "            self.fig = None\n",
    "            self.ax = None\n",
    "    # 可视化状态值\n",
    "    def visualize_state_values(self, state_values: np.ndarray, y_offset: float = 0.2) -> None:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        for state in range(self.size * self.size):\n",
    "            x = state // self.size\n",
    "            y = state % self.size\n",
    "            value_text = f\"{state_values[state]:.1f}\"\n",
    "            self.write_word(pos=(x, y), word=value_text, color='black',\n",
    "                           y_offset=y_offset, size_discount=0.7)\n",
    "    # 可视化策略\n",
    "    def visualize_policy(self, policy: np.ndarray, action_to_direction: dict) -> None:\n",
    "        if self.ax is None:\n",
    "            raise ValueError(\"请先调用create_canvas()创建画布\")\n",
    "        for state in range(self.size * self.size):\n",
    "            x = state // self.size\n",
    "            y = state % self.size\n",
    "            for action in range(len(action_to_direction)):\n",
    "                prob = policy[state, action]\n",
    "                if prob > 0.0:\n",
    "                    direction = action_to_direction[action] * 0.4 * prob\n",
    "                    self.draw_action(pos=[x, y], toward=direction, color='green', radius=0.03 + 0.07 * prob)\n"
   ],
   "id": "7f2aff9c74518abf",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:05:51.653889Z",
     "start_time": "2025-11-18T02:05:51.626743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step4：网格世界环境\n",
    "class GridWorldEnv:\n",
    "    \"\"\"\n",
    "    强化学习网格世界环境\n",
    "    \"\"\"\n",
    "    def __init__(self, size: int, start: Union[list, tuple, np.ndarray],\n",
    "                 target: Union[list, tuple, np.ndarray], forbidden: Union[list, tuple, np.ndarray],\n",
    "                 render_mode: Optional[str] = None, reward_list: Optional[List[float]] = None,\n",
    "                 max_steps: int = 100000):\n",
    "\n",
    "        if size <= 0 or not isinstance(size, int):\n",
    "            raise ValueError(\"网格大小必须为正整数\")\n",
    "\n",
    "        def validate_position(pos, name):\n",
    "            if (pos[0] < 0 or pos[0] >= size or pos[1] < 0 or pos[1] >= size):\n",
    "                raise ValueError(f\"{name}位置必须在网格范围内(0-{size-1})\")\n",
    "            return np.array(pos, dtype=int)\n",
    "\n",
    "        self.time_steps = 0\n",
    "        self.size = size\n",
    "        self.render_mode = render_mode\n",
    "        self.max_steps = max_steps\n",
    "        self.agent_location = validate_position(start, \"起始点\")\n",
    "        self.target_location = validate_position(target, \"目标点\")\n",
    "\n",
    "        self.forbidden_location = []\n",
    "        for fob in forbidden:\n",
    "            fob_pos = validate_position(fob, \"障碍物\")\n",
    "            if np.array_equal(fob_pos, self.agent_location) or np.array_equal(fob_pos, self.target_location):\n",
    "                raise ValueError(\"障碍物不能位于起点或目标点上\")\n",
    "            self.forbidden_location.append(fob_pos)\n",
    "\n",
    "        self.render_ = Render(target=target, forbidden=forbidden, size=size)\n",
    "\n",
    "        # 移除gym依赖，手动定义动作空间和观测空间\n",
    "        self.action_space_size = 5  # 5个动作：停留、上、右、下、左\n",
    "\n",
    "        # 动作到方向向量的映射\n",
    "        self.action_to_direction = {\n",
    "            0: np.array([0, 0]),   # 停留\n",
    "            1: np.array([0, 1]),   # 上\n",
    "            2: np.array([1, 0]),   # 右\n",
    "            3: np.array([0, -1]),  # 下\n",
    "            4: np.array([-1, 0]),  # 左\n",
    "        }\n",
    "\n",
    "        self.reward_list = reward_list if reward_list is not None else [0, 1, -10, -1]\n",
    "\n",
    "        self.Rsa = None\n",
    "        self.Psa = None\n",
    "        self.psa_rsa_init()\n",
    "\n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        if options is not None and \"start\" in options:\n",
    "            start_pos = self.state2pos(options['start'])\n",
    "            start_pos = np.array(start_pos, dtype=int)\n",
    "            if (start_pos[0] < 0 or start_pos[0] >= self.size or\n",
    "                start_pos[1] < 0 or start_pos[1] >= self.size):\n",
    "                raise ValueError(f\"新起点必须在网格范围内(0-{self.size-1})\")\n",
    "            self.agent_location = start_pos\n",
    "        else:\n",
    "            self.agent_location = np.array([0, 0])\n",
    "\n",
    "        self.time_steps = 0\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        if action < 0 or action >= self.action_space_size:\n",
    "            raise ValueError(f\"动作必须在0-{self.action_space_size-1}范围内\")\n",
    "\n",
    "        current_state = self.pos2state(self.agent_location)\n",
    "        reward_index = self.Rsa[current_state, action].tolist().index(1)\n",
    "        reward = self.reward_list[reward_index]\n",
    "\n",
    "        direction = self.action_to_direction[action]\n",
    "        new_pos = self.agent_location + direction\n",
    "        self.render_.upgrade_agent(self.agent_location, direction, new_pos)\n",
    "        self.agent_location = np.clip(new_pos, 0, self.size - 1)\n",
    "\n",
    "        self.time_steps += 1\n",
    "        terminated = np.array_equal(self.agent_location, self.target_location)\n",
    "        truncated = self.time_steps >= self.max_steps\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self) -> None:\n",
    "        if self.render_mode == \"video\":\n",
    "            self.render_.save_video('image/' + str(time.time()))\n",
    "        self.render_.show_frame(100)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\"agent\": self.agent_location, \"target\": self.target_location, \"barrier\": self.forbidden_location}\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {\"time_steps\": self.time_steps}\n",
    "\n",
    "    def state2pos(self, state: int) -> np.ndarray:\n",
    "        return np.array((state // self.size, state % self.size))\n",
    "\n",
    "    def pos2state(self, pos: np.ndarray) -> int:\n",
    "        return pos[0] * self.size + pos[1]\n",
    "\n",
    "    def psa_rsa_init(self):\n",
    "        state_size = self.size ** 2\n",
    "        self.Psa = np.zeros(shape=(state_size, self.action_space_size, state_size), dtype=float)\n",
    "        self.Rsa = np.zeros(shape=(state_size, self.action_space_size, len(self.reward_list)), dtype=float)\n",
    "\n",
    "        for state_index in range(state_size):\n",
    "            for action_index in range(self.action_space_size):\n",
    "                pos = self.state2pos(state_index)\n",
    "                next_pos = pos + self.action_to_direction[action_index]\n",
    "\n",
    "                if next_pos[0] < 0 or next_pos[1] < 0 or next_pos[0] > self.size - 1 or next_pos[1] > self.size - 1:\n",
    "                    self.Psa[state_index, action_index, state_index] = 1\n",
    "                    self.Rsa[state_index, action_index, 3] = 1\n",
    "                else:\n",
    "                    next_state_index = self.pos2state(next_pos)\n",
    "                    self.Psa[state_index, action_index, next_state_index] = 1\n",
    "\n",
    "                    if np.array_equal(next_pos, self.target_location):\n",
    "                        self.Rsa[state_index, action_index, 1] = 1\n",
    "                    elif arr_in_list(next_pos, self.forbidden_location):\n",
    "                        self.Rsa[state_index, action_index, 2] = 1\n",
    "                    else:\n",
    "                        self.Rsa[state_index, action_index, 0] = 1\n",
    "\n",
    "    def get_state_space_info(self):\n",
    "        total_states = self.size ** 2\n",
    "        obstacle_states = [self.pos2state(obs) for obs in self.forbidden_location]\n",
    "        start_state = self.pos2state(self.agent_location)\n",
    "        target_state = self.pos2state(self.target_location)\n",
    "\n",
    "        return {\n",
    "            \"total_states\": total_states,\n",
    "            \"obstacle_states\": obstacle_states,\n",
    "            \"start_state\": start_state,\n",
    "            \"target_state\": target_state,\n",
    "            \"valid_states\": total_states - len(obstacle_states)\n",
    "        }\n"
   ],
   "id": "65dc3cc0d6365519",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:05:51.703871Z",
     "start_time": "2025-11-18T02:05:51.679440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step5：算法求解器\n",
    "class Solver:\n",
    "    \"\"\"\n",
    "    强化学习算法求解器\n",
    "    - 值迭代：先估算每个位置的价值，再决定怎么走\n",
    "    - 策略迭代：先随便走，然后根据结果改进走法\n",
    "    \"\"\"\n",
    "    def __init__(self, env: GridWorldEnv, gamma: float = 0.9):\n",
    "        self.gamma = gamma  # 选择最优的概率？\n",
    "        self.env = env  # 网格环境\n",
    "        self.action_space_size = env.action_space_size      # 活得空间大小，上、下、左、右、不动\n",
    "        self.state_space_size = env.size ** 2       # 状态空间，一共有多少格\n",
    "        self.reward_space_size, self.reward_list = len(self.env.reward_list), self.env.reward_list      # 奖励值列表大小和里面的奖励值 [普通移动，达到目标，撞到障碍物，撞到边界]\n",
    "\n",
    "        self.state_value = np.zeros(shape=self.state_space_size)        # 状态值，先初始所有状态值为0\n",
    "        self.qvalue = np.zeros(shape=(self.state_space_size, self.action_space_size))       # q值\n",
    "        self.mean_policy = np.ones(shape=(self.state_space_size, self.action_space_size)) / self.action_space_size      # 平均策略\n",
    "        self.policy = self.mean_policy.copy()       # 策略\n",
    "\n",
    "    def random_greedy_policy(self):\n",
    "        \"\"\"\n",
    "        生成随机贪心策略\n",
    "        \"\"\"\n",
    "        policy = np.zeros(shape=(self.state_space_size, self.action_space_size))\n",
    "        for state_index in range(self.state_space_size):\n",
    "            action = np.random.choice(range(self.action_space_size))\n",
    "            policy[state_index, action] = 1\n",
    "        return policy\n",
    "\n",
    "    def policy_evaluation(self, policy: np.ndarray, tolerance: float = 0.001, max_iterations: int = 1000):\n",
    "        \"\"\"\n",
    "        策略评估\n",
    "        \"\"\"\n",
    "        state_value_current = np.ones(self.state_space_size)\n",
    "        state_value_previous = np.zeros(self.state_space_size)\n",
    "\n",
    "        iterations = 0\n",
    "        while np.linalg.norm(state_value_current - state_value_previous, ord=1) > tolerance and iterations < max_iterations:\n",
    "            state_value_previous = state_value_current.copy()\n",
    "            for state in range(self.state_space_size):\n",
    "                value = 0\n",
    "                for action in range(self.action_space_size):\n",
    "                    value += policy[state, action] * self.calculate_qvalue(state=state, action=action, state_value=state_value_current.copy())\n",
    "                state_value_current[state] = value\n",
    "            iterations += 1\n",
    "        return state_value_current\n",
    "\n",
    "    def policy_improvement(self, state_value: np.ndarray):\n",
    "        \"\"\"\n",
    "        策略改进\n",
    "        \"\"\"\n",
    "        improved_policy = np.zeros(shape=(self.state_space_size, self.action_space_size))\n",
    "        state_value_k = state_value.copy()\n",
    "\n",
    "        for state in range(self.state_space_size):\n",
    "            qvalue_list = []\n",
    "            for action in range(self.action_space_size):\n",
    "                qvalue_list.append(self.calculate_qvalue(state, action, state_value.copy()))\n",
    "            action_star = qvalue_list.index(max(qvalue_list))\n",
    "            improved_policy[state, action_star] = 1\n",
    "            state_value_k[state] = max(qvalue_list)\n",
    "\n",
    "        return improved_policy, state_value_k\n",
    "\n",
    "    def calculate_state_values_from_qvalues(self, qvalues: np.ndarray, policy = None):\n",
    "\n",
    "        state_values = np.zeros(shape=self.state_space_size)\n",
    "        for state in range(self.state_space_size):\n",
    "            if policy is None:\n",
    "                state_values[state] = np.max(qvalues[state])\n",
    "            else:\n",
    "                state_values[state] = np.sum(policy[state] * qvalues[state])\n",
    "        return state_values\n",
    "\n",
    "    def calculate_qvalue(self, state: int, action: int, state_value: np.ndarray):\n",
    "        \"\"\"\n",
    "        计算Q值\n",
    "        Q(s,a) = 立即奖励 + 未来奖励的期望\n",
    "        \"\"\"\n",
    "        qvalue = 0\n",
    "        for i in range(self.reward_space_size):\n",
    "            qvalue += self.reward_list[i] * self.env.Rsa[state, action, i]\n",
    "        for next_state in range(self.state_space_size):\n",
    "            qvalue += self.gamma * self.env.Psa[state, action, next_state] * state_value[next_state]\n",
    "        return qvalue\n",
    "\n",
    "    def value_iteration(self, tolerance: float = 0.001, max_iterations: int = 1000):\n",
    "        \"\"\"\n",
    "        值迭代算法\n",
    "        算法步骤：\n",
    "        1. 初始化状态价值\n",
    "        2. 不断更新：V(s) = max[Q(s,a) for all a]\n",
    "        3. 直到价值函数收敛\n",
    "        4. 从最终的价值函数导出最优策略\n",
    "        \"\"\"\n",
    "        state_value_previous = np.zeros(self.state_space_size)\n",
    "        self.state_value = np.ones(self.state_space_size)\n",
    "\n",
    "        remaining_iterations = max_iterations\n",
    "        while np.linalg.norm(self.state_value - state_value_previous, ord=1) > tolerance and remaining_iterations > 0:\n",
    "            remaining_iterations -= 1\n",
    "            state_value_previous = self.state_value.copy()\n",
    "            self.policy, self.state_value = self.policy_improvement(self.state_value)\n",
    "\n",
    "        return self.policy, self.state_value, remaining_iterations\n",
    "\n",
    "    def policy_iteration(self, tolerance: float = 0.001, max_iterations: int = 100):\n",
    "        \"\"\"\n",
    "        策略迭代算法\n",
    "        算法步骤：\n",
    "        1. 初始化一个随机策略\n",
    "        2. 策略评估：计算当前策略的价值\n",
    "        3. 策略改进：基于价值函数改进策略\n",
    "        4. 重复2-3直到策略不再改变\n",
    "        \"\"\"\n",
    "        policy_previous = np.zeros(shape=(self.state_space_size, self.action_space_size))\n",
    "        self.policy = self.random_greedy_policy()\n",
    "\n",
    "        remaining_iterations = max_iterations\n",
    "        while np.linalg.norm(self.policy - policy_previous, ord=1) > tolerance and remaining_iterations > 0:\n",
    "            remaining_iterations -= 1\n",
    "            policy_previous = self.policy.copy()\n",
    "            self.state_value = self.policy_evaluation(self.policy, tolerance, max_iterations)\n",
    "            self.policy, _ = self.policy_improvement(self.state_value.copy())\n",
    "\n",
    "        return self.policy, self.state_value, remaining_iterations\n",
    "\n",
    "    def show_policy(self, policy = None, render_mode: str = 'show'):\n",
    "        self.env.render_.visualize_policy(\n",
    "            policy=policy if policy is not None else self.policy,\n",
    "            action_to_direction=self.env.action_to_direction\n",
    "        )\n",
    "        if render_mode == 'show':\n",
    "            self.env.render_.show_frame(t=5, close_after=False)\n",
    "\n",
    "    def show_state_value(self, state_value = None, y_offset: float = 0.2, render_mode: str = 'show'):\n",
    "        self.env.render_.visualize_state_values(\n",
    "            state_values=state_value if state_value is not None else self.state_value,\n",
    "            y_offset=y_offset\n",
    "        )\n",
    "        if render_mode == 'show':\n",
    "            self.env.render_.show_frame(t=5, close_after=False)"
   ],
   "id": "9414546532f7be40",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step6: 运行示例\n",
    "print(\"创建网格世界环境...\")\n",
    "env = GridWorldEnv(\n",
    "    size=5,\n",
    "    start=[0, 0],\n",
    "    target=[2, 3],\n",
    "    forbidden=[[1, 1], [2, 1], [2, 2], [1, 3], [1, 4], [3, 3]],\n",
    "    render_mode='',\n",
    "    reward_list=[0, 1, -10, -1]  # [普通移动，达到目标，撞到障碍物，撞到边界]\n",
    ")\n",
    "# 可视化策略和状态值\n",
    "print(\"状态空间信息:\", env.get_state_space_info())\n",
    "\n",
    "# 创建求解器并运行值迭代算法\n",
    "solver = Solver(env, gamma=0.9)\n",
    "# 创建随机策略\n",
    "random_policy = solver.random_greedy_policy()\n",
    "# 展示随机策略\n",
    "solver.show_policy(policy=random_policy,render_mode='show')"
   ],
   "id": "750b8a61313c43f1",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:05:51.986625Z",
     "start_time": "2025-11-18T02:05:51.981415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Step6: 运行示例\n",
    "# print(\"创建网格世界环境...\")\n",
    "# env = GridWorldEnv(\n",
    "#     size=5,\n",
    "#     start=[0, 0],\n",
    "#     target=[2, 3],\n",
    "#     forbidden=[[1, 1], [2, 1], [2, 2], [1, 3], [1, 4], [3, 3]],\n",
    "#     render_mode='',\n",
    "#     reward_list=[0, 1, -10, -1]  # [普通移动，达到目标，撞到障碍物，撞到边界]\n",
    "# )\n",
    "# # 可视化策略和状态值\n",
    "#\n",
    "# print(\"状态空间信息:\", env.get_state_space_info())\n",
    "#\n",
    "# # 创建求解器并运行值迭代算法\n",
    "# solver = Solver(env, gamma=0.9)\n",
    "# start_time = time.time()\n",
    "#\n",
    "# # 选择要运行的算法\n",
    "# print(\"运行值迭代算法...\")\n",
    "# policy, state_value, remaining_iterations = solver.value_iteration()\n",
    "# end_time = time.time()\n",
    "# cost_time = end_time - start_time\n",
    "# # print(\"运行策略迭代算法...\")\n",
    "# # policy, state_value, remaining_iterations = solver.policy_iteration()\n",
    "# solver.show_policy(policy=solver.policy, render_mode='show')\n",
    "# solver.show_state_value(state_value=solver.state_value, y_offset=0.2, render_mode='show')\n",
    "# print(f\"算法耗时: {round(cost_time, 4)} 秒, 剩余迭代次数: {remaining_iterations}\")\n",
    "# print(\"策略矩阵:\")\n",
    "# print(policy)\n",
    "# print(\"状态值函数:\")\n",
    "# print(state_value)\n",
    "# print(\"演示完成！\")"
   ],
   "id": "45bf746115bd1c32",
   "outputs": [],
   "execution_count": 161
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
